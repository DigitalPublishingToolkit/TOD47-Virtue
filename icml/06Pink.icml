<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<?aid style="50" type="snippet" readerVersion="6.0" featureSet="513" product="8.0(370)" ?>
<?aid SnippetType="InCopyInterchange"?>
<Document DOMVersion="8.0" Self="pandoc_doc">
    <RootCharacterStyleGroup Self="pandoc_character_styles">
      <CharacterStyle Self="$ID/NormalCharacterStyle" Name="Default" />
      <CharacterStyle Self="CharacterStyle/Cite" Name="Cite">
        <Properties>
          <BasedOn type="object">$ID/NormalCharacterStyle</BasedOn>
        </Properties>
      </CharacterStyle>
      <CharacterStyle Self="CharacterStyle/Italic" Name="Italic" FontStyle="Italic">
        <Properties>
          <BasedOn type="object">$ID/NormalCharacterStyle</BasedOn>
        </Properties>
      </CharacterStyle> 
    </RootCharacterStyleGroup>
    <RootParagraphStyleGroup Self="pandoc_paragraph_styles">
      <ParagraphStyle Self="$ID/NormalParagraphStyle" Name="$ID/NormalParagraphStyle"
          SpaceBefore="6" SpaceAfter="6"> <!-- paragraph spacing -->
        <Properties>
          <TabList type="list">
            <ListItem type="record">
              <Alignment type="enumeration">LeftAlign</Alignment>
              <AlignmentCharacter type="string">.</AlignmentCharacter>
              <Leader type="string"></Leader>
              <Position type="unit">10</Position> <!-- first tab stop -->
            </ListItem>
          </TabList>
        </Properties>
      </ParagraphStyle>
      <ParagraphStyle Self="ParagraphStyle/Footnote &gt; Paragraph" Name="Footnote &gt; Paragraph" LeftIndent="0">
        <Properties>
          <BasedOn type="object">$ID/NormalParagraphStyle</BasedOn>
        </Properties>
      </ParagraphStyle>
      <ParagraphStyle Self="ParagraphStyle/Header1" Name="Header1" LeftIndent="0" PointSize="36">
        <Properties>
          <BasedOn type="object">$ID/NormalParagraphStyle</BasedOn>
        </Properties>
      </ParagraphStyle>
      <ParagraphStyle Self="ParagraphStyle/Header2" Name="Header2" LeftIndent="0" PointSize="30">
        <Properties>
          <BasedOn type="object">$ID/NormalParagraphStyle</BasedOn>
        </Properties>
      </ParagraphStyle>
      <ParagraphStyle Self="ParagraphStyle/Header3" Name="Header3" LeftIndent="0" PointSize="24">
        <Properties>
          <BasedOn type="object">$ID/NormalParagraphStyle</BasedOn>
        </Properties>
      </ParagraphStyle>
      <ParagraphStyle Self="ParagraphStyle/Paragraph" Name="Paragraph" LeftIndent="0">
        <Properties>
          <BasedOn type="object">$ID/NormalParagraphStyle</BasedOn>
        </Properties>
      </ParagraphStyle> 
    </RootParagraphStyleGroup>
    <RootTableStyleGroup Self="pandoc_table_styles">
      <TableStyle Self="TableStyle/Table" Name="Table" />
    </RootTableStyleGroup>
    <RootCellStyleGroup Self="pandoc_cell_styles">
      <CellStyle Self="CellStyle/Cell" AppliedParagraphStyle="ParagraphStyle/$ID/[No paragraph style]" Name="Cell" />
    </RootCellStyleGroup>
  <Story Self="pandoc_story"
      TrackChanges="false"
      StoryTitle=""
      AppliedTOCStyle="n"
      AppliedNamedGrid="n" >
    <StoryPreference OpticalMarginAlignment="true" OpticalMarginSize="12" />

<!-- body needs to be non-indented, otherwise code blocks are indented too far -->
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Header1">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Extractivist Ethics</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Header3">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Sarah Pink</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Header2">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Introduction</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Let me take you to the moment I started to write this chapter about AI, ethics, and people, following links through reports and papers on ethics I found the AI4People’s ethical framework. The intentions of such projects have societal wellbeing at heart, and contribute actively to the important argument that AI needs to be regulated and needs to do good. This made me feel uncomfortable as I began to read; knowing I was about to turn my anthropologist’s eye to critique the logics of an agenda that seeks to make AI ethical, when surely I should be on the same page (</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Spoiler alert: hold onto the page metaphor and don’t click on the links until I ask you to</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>). To be clear, my critique is not of the AI4People’s ethical framework in particular. Rather, the framework exemplifies how the metaphors, narratives, and structures that commonly frame good intentions towards ethical AI and People in dominant discourses betray a logic that is misaligned with everyday realities. My agenda, and my work as a whole, focuses on creating collaborative partnerships to work toward ethical futures, rather than simply writing endpoint outlines of what is wrong. But to make the connections/relations required for collaboration we need to make visible the cracks between approaches, disciplines, and logics.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>The ‘AI4People’s Ethical Framework for a Good AI Society: Opportunities, Risks, Principles and Recommendations’ report is ‘committed to the development of AI technology in a way that secures people’s trust, serves the public interest, and strengthens shared social responsibility’ and it presents a set of recommendations towards ensuring this.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>L. Floridi, J. Cowls, M. Beltrametti, et al. ‘AI4People—An Ethical Framework for a Good AI Society: Opportunities, Risks, Principles, and Recommendations’, </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Minds &amp; Machines</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content> 28, (2018): 22, https://www.eismd.eu/wp-content/uploads/2019/11/AI4People%E2%80%99s-Ethical-Framework-for-a-Good-AI-Society_compressed.pdf.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> It is authored by a range of scholars and industry contributors who specialize in ethics from fields including philosophy, law, and computer science, but excluding the social sciences such as anthropology and qualitative sociology. While the report presents perfectly reasonable principles from the perspective of the societal structures in which we presently operate, the terminologies and concepts it uses to communicate its ideas are difficult to reconcile with those of an anthropological approach to people, ethics, and emerging technologies. First, the idea that people’s trust can be ‘secured’ by particular developments in AI technology requires trust to be a fixed quality that can be extracted from people and captured. Second, the notion of ‘the public interest’ invokes a one-dimensional framing of people, rather than actual people in the messy contingency of their lives where real interests and everyday ethics play out. Third, by referring to ‘social responsibility,’ it focuses on a sociological unit or level of analysis, rather than on the experiential domain of life. That is, the AI4People agenda is inhabited by a striking absence of the experience and activity of actual people.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>In this chapter I argue for a people-focused approach which must be surfaced through engagement with theory and research in everyday worlds. Elsewhere I have defined ‘techno-solutionist approaches to ethics as extractivist, where they seek to identify and capture human ethics values and invest them in machines with the intention that such ethical machines will engender trust.’</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>S. Pink, ‘Trust, Ethics and Automation: Anticipatory Imaginaries in Everyday Life’ in S. Pink, D. Lupton, M. Berg &amp; M. Ruckenstein (eds) </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Everyday Automation</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>, London: Routledge, 2022.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> Here, I extend this argument, along with the premise that to be ethical, AI should not simply be for people, but be designed with people, attentive to diversity, specificity and locality. It should not seek to secure, gain or win people’s trust or anything else after the event of its design, but should be created already within relations of trust, attentive to ‘everyday ethics’.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>Pink, ‘Trust, Ethics and Automation’.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> By everyday ethics I mean ethics as they are lived out in and contingent on the circumstances of everyday life; where ethics are not necessarily fixed in such a way that they can be applied consistently across all situations, and are nuanced by the relationships between people, things and environment. My definition builds on ethics as understood in phenomenological anthropology, which ‘reveals ethical life as a condition marked by ontological indeterminacy and ethical overload;’</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>C. Mattingly and J. Throop, ‘The Anthropology of Ethics and Morality’, </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Annual Review of Anthropology</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content> 47.1 (2018): 483.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> in anthropology (as I practice it) ethics are indeterminate, ‘contingent, emergent from the everyday worlds and circumstances of life.’</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>Pink, ‘Trust, Ethics and Automation’.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> Such an understanding of ethics permeates anthropological research ethics as well as how we understand other people’s ethics, and thus concerns equally the actions of the reflexive ethnographer.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>M. Strathern (ed) </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Audit Cultures: Anthropological Studies in Accountability</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>, London: Routledge, 2000; P. Pels, ‘The Trickster’s Dilemma: Ethics and the Technologies of the Anthropological Self’ in M. Strathern (ed) </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Audit Cultures</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>The AI4People’s agenda is of course not alone in its approach, and it seeks to offer a solution to the question of how to make AI ethical, which aligns with the ways AI is being developed. In one sense, this is a step in an ethical direction. But it is also emblematic of a consistent and glaring gap in the dominant discourses advanced in the technology industry, government, and the engineering and computer sciences about how to make AI ethical. I believe that there is a common concern about people and AI across these disciplines and stakeholders, which we can better address by bringing people (encountered through collaborative ethnographic research practices, engagements, and interventions) into the debate. This means we need to ensure that everyday ways of knowing and diversity are at the forefront of the ways we consider ethics. But a glance at the AI4People report’s web page</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>https://www.eismd.eu/featured/ai4peoples-ethical-framework-for-a-good-ai-society/.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> banner (</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>go to the link now</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>) assures me that the page is visibly gendered. Although the report itself was authored by men and women, this appears to be erased in the visual representation of the banner. The substantially outed</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Cite">
          <Content>@allmalepanels</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>, https://twitter.com/allmalepanels?lang=en.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> and critiqued ‘manel’ (all male panel)</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>J.K. Rodriguez and E.A. Guenther, ‘What’s Wrong With “Manels” and what Can We Do About Them?’ The Conversation, 15 October 2020, https://theconversation.com/whats-wrong-with-manels-and-what-can-we-do-about-them-148068.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> lives on, and highlights that the topic of extractivist ethics I am about to address also surfaces the gendered politics of technology, data, ethics, and academia.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Header2">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Extractivist ethics (mining for ethics)</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>The metaphors we use to refer to data, as well as automated, connected, and intelligent emerging technologies and systems are themselves sites of contestation, and with that they also constitute possible sites of investigation and intervention. Sally Wyatt suggests that as critical social scientists we need to contest the extractive metaphors used by industry and policy makers which frame data as a resource that can be mined.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>S. Wyatt, ‘Metaphors in Critical Internet and Digital Media Studies’, </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>New Media &amp; Society</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>, 23.2 (2021): 406–16.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> In this chapter I outline a related mode of contestation, which instead of switching the metaphors involves applying them to ethics in order to interrogate how ethics are situated within approaches to data and emerging technologies such as AI, which scholars have already labelled as being extractivist.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>S. Jasanoff, </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>The Ethics of Invention</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>. New York: W. W. Norton &amp; Company, 2016; Wyatt, ‘Metaphors’.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> I discuss how similar logics of extraction, which have been critiqued by critical data scholars, are applied to ethics in AI, and what this suggests regarding industry, policy, and research. I call this </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>extractivist ethics. </Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>So how are extractivist ethics constituted? On one level, as exemplified above, ethics become the bait through which trust in technology is extracted from publics or users. On another, as I have proposed elsewhere, in relation to the relationship between trust and ethics, techno-solutionist approaches to ethics can be defined as extractivist where ‘they seek to identify and capture human ethics values and invest them in machines with the intention that such ethical machines will engender trust.’</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>Pink, ‘Trust, Ethics and Automation’.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> This kind of causality typifies renderings of ethics in the engineering sciences. A good example is the well-known MIT moral machine experiment,</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>E. Awad, S. Dsouza, R. Kim et al</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>.</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>, ‘The Moral Machine Experiment’, </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Nature</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>, 563 (2018): 59–64. See also: https://www.moralmachine.net/.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> which I (and others) have discussed elsewhere,</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>S. Pink, K. Raats, T. Lindgren, K. Osz, and V. Fors, ‘An Interventional Design Anthropology of Emerging Technologies’ in Maja Hojer Bruun, Ayo Wahlberg,  Dorthe Brogaard Kristensen, Rachel Douglas-Jones,  Cathrine Hasse,  Klaus Høyer, and Brit Ross Winthereik (eds) </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>The Handbook for the Anthropology of Technology</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>, London: Palgrave, 2021; Pink, ‘Trust, Ethics and Automation’.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> but here take up in a new direction.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>The moral machine is a game which serves as survey seeking to extract the moral judgments of thousands of people across the world in relation to a set of future self-driving car scenarios based on the ‘Trolley Problem’ (a philosophical conundrum where the person playing the game needs to decide whom from a choice of possible victims the train car should kill in an accident) by judging a series of scenarios presented online. There is perhaps nothing surprising that a game should be used to extract ethics from its players. Writing more generally of social media, Sheila Jasanoff notes how such technologies ‘profit from people’ by ‘mining their thoughts, words, habits, bodies and emotions as resources to create new marketable goods.’</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>Jasanoff, 259.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> Edmond Awad and colleagues (all men), have good intentions, as the AI4People authors discussed above. They are attentive to cultural difference and suggest that ‘we can embrace the challenges of machine ethics as a unique opportunity to decide, as a community, what we believe to be right or wrong; and to make sure that machines, unlike humans, unerringly follow these moral preferences.’</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>Awad et al., 63.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> Again, my quarrel is not so much with the sentiment but with an understanding of ethics which is disconnected from all the anthropological evidence of how ethics actually play out in the contingent circumstances of the everyday. As the philosopher Onora O’Neill has highlighted, the use of surveys or polls to quantify human sentiment, affective states, and contingent decisions is limited. For instance, polls on public trust ‘offer no evidence about the judgements that people make when they decide to trust or refuse trust to particular individuals or institutions for particular matters, in which they often differentiate cases with some care.’</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>O. O’Neill, ‘Accountable Institutions, Trustworthy Cultures’, </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Hague J Rule Law</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content> 9 (2017): 405.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> Equally questionable is the status of knowledge about ethics derived from responses to improbable ethical dilemmas which are subsequently suspended from their sources, rather than situated within realistic situations in which they actually unfold.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>The implication of understanding ethics as contingent (as argued earlier) is that everyday ethics are slippery, they are incredibly difficult to capture, to invest in either organizations or machines, or to regulate. Thus, it follows that the assumptions it is possible to solve ethical problems that emerge after AI has become embedded in everyday life are limited. Typical solutions involving either designing ethical machines, or introducing regulation and governance, construct risk mitigation processes, based on logics which follow causal chains created externally to everyday life and its ethics. When instead we turn the focus to what it actually means to be human in the everyday—that is, the experience of being, feeling, and doing, ethics cannot be abstracted, fixed, or predetermined externally to the everyday. Instead, through giving ‘primacy to first- and second- person positions’, phenomenology draws our attention to the intersubjectivity and intercorporeality of ethics.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>Mattingly and Throop, 483.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> As Mattingly and Throop put it, ‘Far from being a site of culturally well-articulated obligations or the imposition of normative moral orders that create docile subjects, scholars have empirically documented ways that the ethical can pose excessive demands that render lived experience uncanny.’</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>Mattingly and Throop, 485-6.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> This means that while there are ongoing attempts to abstract ethics into regulations, such ethics are unlikely to ever be aligned with the ethical requirements of everyday life.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>As such, in this section I have offered two very different answers to questions of the kind invoked by legal and STS scholar Sheila Jasinoff when she asks: ‘Whose duty is it in today’s complex societies to foresee or forestall the negative impacts of technology, and do we possess the necessary tools and instruments for forecasting and preventing harm?’</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>Jasanoff, 7.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> The MIT moral machine experiment tries to answer this question head on by both taking responsibility for forestalling the negative and creating tools through which to create ethical self-driving cars that people will subsequently trust and adopt, and in doing so reduce traffic deaths and carbon emissions. But Mattingly and Throop ask a different question, which complicates both this response and the mode of responsibility it assumes: ‘What is at stake in emphasizing the underdetermined nature of ethical life […]? What does it mean to portray the human as characterized by potentiality or possibility rather than actuality? What does it mean to claim that there is an excessiveness to the ethical demand such that it cannot be reduced to following prescriptive norms or rules?’</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>Mattingly and Throop, ‘The Anthropology of Ethics and Morality’, 486.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> In this context the answer is that because the ethics that will characterize the relations between people and self-driving cars (and by extension AI in general) are indeterminate, they can neither be extrapolated to machines nor be engaged to forecast and prevent harm.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Header2">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Extractivist Ethics and Anticipatory Audits (Attracting Investment)</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>In this section I investigate how extractivist ethics could participate in the anticipatory visions of capitalism. These visions are key to capitalism occupying the future to maintain its structural hold on everyday life. As a resource that can be extracted, or as a bait to capture trust, ethics can be invested in trustworthy intelligent and automated machines, thus serving as the catalyst in causal chains of human trust, acceptance, and adoption of AI. Here, extracted ethics could participate in creating an anticipatory infrastructure through which ethical AI and ethical machines are seen as a technological solution to situations where public acceptance of automated technologies is perceived as a challenge,</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>J. Stilgoe, T. Cohen, ‘Rejecting Acceptance: Learning from Public Dialogue on Self-Driving Vehicles’, </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Science and Public Policy</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>, 48.6 (2021): 849–59.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> and thus to attract investment in the technologies that are envisioned as solutions to societal problems.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>To make investment and markets for AI plausible and realistic, extractivist ethics are also aligned with what I call the </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>anticipatory audit</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>. Anticipatory audits are part of what anthropologists have long since referred to as ‘audit cultures.’</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>For example, Strathern, </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Audit Cultures</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> Many elements of audit culture are anticipatory by nature. Take, for example, university ethics committees.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>S. Pink, ‘Ethics in a Changing World: Embracing Uncertainty, Understanding Futures, and Making Responsible Interventions’ in (eds) S. Pink, V. Fors, T. O’Dell </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Working in the Between: Theoretical Scholarship and Applied Practice</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>, Oxford: Berghahn, 2017. To be clear, I support ethical review processes because when they are done well, they provoke reflection as well as ethical conduct.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> This is an example I have discussed often but it is worth repeating here because it both connects with the academic research and funding context mentioned below, and is likely part of the experience of academic readers. Usually regulated by an institutional (or in some case national) body which sets the rules which define ethical research conduct, ethical approval involves ensuring that any risks of what is defined as unethical happening in our research are identified and mitigated </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>in advance.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> However, when ethics are the subject of an anticipatory audit, the only way that ethics can be accounted for is by fixing them still, capturing them for measurement against ethical regulations. The result is to reassure our institutions that our research will in fact be ethical (and that they have minimized the possibility of conduct that would be interpreted as unethical). The case of ethical AI is similar in that the ethical conditions that AI should manifest are prescribed in advance through ethics frameworks, and can therefore, like the ethics of researchers, the ethics of AI can also be audited before they are let loose into the world—that is, into everyday life environments.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>As one of many examples, the website of the top consultancy firm PricewaterhouseCoopers (PwC) takes up the question of ‘Responsible AI (RAI)’, which it states ‘is the only way to mitigate AI risks.’</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>PwC, https://www.pwc.com/gx/en/issues/data-and-analytics/artificial-intelligence/what-is-responsible-ai.html.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> Their ‘Responsible AI Toolkit’ includes a focus on ethics. Yet while the possibility that getting the ethics right will mitigate the risks is tempting to believe, what that actually means still appears to be in the balance; a 2019 review of international ethics frameworks found ‘a global convergence emerging around five ethical principles [for AI] (transparency, justice and fairness, non-maleficence, responsibility and privacy), with substantive divergence in relation to how these principles are interpreted, why they are deemed important, what issue, domain or actors they pertain to, and how they should be implemented.’</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>A. Jobin, M. Ienca, and E. Vayena, ‘The Global Landscape of AI Ethics Guidelines’, </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Nat Mach Intell</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content> 1 (2019): 389.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> Moreover, in 2021 the Pew Research Institute issued the findings of their survey of technology experts, to suggest that most did not believe that ethical AI design would be broadly adopted by 2030.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>https://www.pewresearch.org/internet/2021/06/16/experts-doubt-ethical-ai-design-will-be-broadly-adopted-as-the-norm-within-the-next-decade/.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>However, of the most significant comments cited by the Pew were those by danah boyd, who pointed out that when AI systems are aligned with contemporary capitalism, ‘which fetishizes efficiency, scale and automation,’ they are antithetical to the ethical values of ‘augmentation, localized context and inclusion.’ boyd’s insight connects with the everyday ethics outlined above, which emphasizes precisely how ethics are contingent and specific. As these points show, it is not just a question of what the ethics of AI are, but also a question of where it gets its ethics from and whose values they align with. As I have shown through the example of the moral machine experiment, there have been attempts to extract the ethics from the everyday by aggregating individual responses, but these inevitably fail to generate ethics that align with ethics in the everyday because they are extractive. We cannot mine ethics. Rather we have to get in there with them. It is the opposite of extraction; it requires blending and collaboration both in place and with the ongoing emergence of life.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Indeed, the similarities between the anticipatory ethics audits we experience as university academics and those AI systems are subject to don’t stop at their common impulse to mitigate the risks related to what certain agents will do ‘in the wild.’ Both modes of anticipatory audit are also meant to account for, regulate, control, and mitigate any risks involved in the ethical behaviour of an active agent in the form of the AI or the researcher, over a passive agent in the form of a member of the public, a user or consumer, or a research participant. There are, however, several mismatches between anticipatory audits of ethics and the everyday ethics in which the academic researchers or the AI systems and technologies (who or which have been audited) will be let loose. The everyday worlds where their anticipated one-way ethical effects will be activated are in fact inhabited by very different ethics—the experiential ethics noted by Mattingly and Throop, which are contingent, contextual, embodied, intersubjective, and indeterminate.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>Mattingly and Throop, ‘The Anthropology of Ethics and Morality’.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Header2">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Funding Extractivist Ethics (The Gender of Funding)</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Above I have outlined the inherent flaw in visions of human ethics as a determinate thing which can be extracted from society or garnered from experts as representing societal values, captured, and transferred into a machine.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>In this chapter I raise this issue specifically in relation to the question of the challenge of making ethical machines. This issue raises wider questions relating to how such a stance might be reconciled with the status of ethics, regulation, and governance in society, which is not within the scope of this chapter to address.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> Yet such approaches to ethics offer a (deceptively) simple response to a complex problem, with a causal chain of guarantees which mitigate the risks of AI doing future harm, </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>as well as</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> mitigating a set of risks around the research needed to create the knowledge and technologies that will apply the solution.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Research that proposes to embed predetermined ethical values into AI is relatively not risky because it shows a clear route to impact. It might, of course, entail other risks relating to the difficulties or uncertainties related to the technological discoveries that the researchers wish to make, which is a different thing. However, if you already believe that ethical AI—AI infused with societally endorsed ethical values—will make people trust, accept, and adopt technology that will benefit society and the environment, it’s not a big leap to consequently assume that it’s a good idea to fund research that will aim to produce AI that will only act according to desirable human ethics, and that will be governed by an ethics framework approved by experts. Thus an extractivist ethics agenda would ultimately be appealing to well-intentioned organizations and researchers involved in narratives and practices of dominant innovation agendas. It would subsequently support the academic careers of those whose work is funded through them, and oil the wheels of the machines of research funding, outputs, and impact that govern success in academia. One of the factors that appears to govern success in academia, at least in funding outputs, is gender. In 2019 an EU H2020 funded project titled ‘Grant Allocation Disparities from a Gender Perspective’ reported a set of ‘indisputable facts:’ there are fewer women than men in STEM disciplines and in senior academic positions, and women get fewer research grants, less funding, and lower evaluations.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>L. Cruz Castro and L. Sans Menéndez, </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Literature Review Synthesis Report.</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content> CSIS Institute of Public Goods and Policies, Madrid, 2019.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Header2">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Extractivist Ethics and Everyday Ethics at the Impasse</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>In this chapter, I have proposed the concept of </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>extractivist ethics</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>, which I suggest creates a category through which to reveal and contest the dominant narratives concerning the generation of trust and acceptance of and the constitution of markets for emerging technologies in society. I have explored the alignment of </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>extractivist ethics</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> to another concept—the </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>anticipatory audit.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> I have suggested the risk mitigation paradigm that structures both extractivist ethics and the anticipatory audit, also aligns them to both corporate and research agendas, because they both promise paths to impact.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Approaches to ethical AI that call for ethics frameworks and regulation have good intentions. Luciano Floridi is right to advocate that ‘Ethics-first is the right approach to set global standards for AI.’</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>L. Floridi, ‘Establishing the Rules for Building Trustworthy AI’, </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Nat Mach Intell</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content> 1 (2019): 262.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> However, for ethics to really come first, more work is needed. At the moment the logics of ethics from above through regulation are not compatible with ethics as they occur in the everyday contexts that they ultimately seek to (ethically) impact on. Everyday ethics cannot entertain the certainties that extractivist ethics, as articulated in relation to ethical machines, desire. In part this concurs with another point boyd makes in the Pew Survey, that ‘[w]e misunderstand ethics when we think of it as a binary, when we think that things can be ethical or unethical;’ such binaries indeed coincide with the idea that machines can be made ethical. Seeing ethics participating in predictable causal sequences is similarly incorrect. Ethics cannot participate in predictable chains of reactions, simply because they are not static. These anthropological interpretations of ethics complicate the STEM models of ethical machines and their promise of beneficial impact on society. They are moreover difficult to work with, and teach, because they are slippery, tricky, and don’t stay still. But besides this they proffer another challenge to the societal structures that make STEM valued in research because as boyd puts it: ‘We cannot meaningfully talk about ethical AI until we can call into question the logics of late-stage capitalism.’</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>There is a politics to everyday ethics, which, as I hinted at the beginning of this chapter, which also requires us to attend to questions of gender. Gender is intersectional, not binary, meaning that both my own references to all male panels, research teams and the possibility of bias in research funding outcomes towards men, all need to be nuanced with other modes of difference, inequality, and inequity. However, the evidence suggests that AI is emerging within a gendered enterprise of research and development, which frequently favours men, and to move forward we need to empower other voices. A starting point could be to borrow Point 6 of the Feminist Data Manifest-no,</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>​​Feminist Data Manifest-No, https://www.manifestno.com/home; Point 6 of the Feminist Data Manifesto reads: ‘We refuse the expansion of forms of data science that normalizes a condition of data extractivism and is defined primarily by the drive to monetize and hyper-individualize the human experience. We commit to centering creative and collective forms of life, living, and worldmaking that exceed the neoliberal logics and resist the market-driven forces to commodify human experience.’</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> to ‘refuse the expansion of forms of [data science] </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>ethics frameworks</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> that normalize[s] a condition of [data] </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>ethics</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> extractivism and is defined primarily by the drive to monetize and hyper-individualize the human experience.’ When ethics (as facets of human experience) are extracted from the everyday, or are used as bait to capture other everyday feelings like trust, in order to constitute anticipated markets, they are effectively being commodified. Like feminist data scholars we should instead: ‘commit to centering creative and collective forms of life, living, and worldmaking that exceed the neoliberal logics and resist the market-driven forces to commodify human experience’.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Header2">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Acknowledgments</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>This chapter has benefited from its original conceptualisation as part of the excellent Economies of Virtue workshop. I thank Thao Phan, Monique Mann, Jake Goldenfein, and Declan Kuch for their work and inspiration and I am especially grateful to Ellen Broad, Lorenn Ruster, Jake Goldenfein, and Declan Kuch for their wonderfully inspiring comments and review of the first version of this chapter.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Header2">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Funding Disclosure</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>My work on this chapter is undertaken in my role as a Chief Investigator in the Australian Research Council–funded Centre of Excellence for Automated Decision-Making and Society (CE200100005) (2020–2027).</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Header2">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>References</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Awad, E., Dsouza, S., Kim, R. et al</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> ‘The Moral Machine Experiment‘, </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Nature</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> 563 (2018): 59–64.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Cruz Castro, L. and Sans Menéndez, L. </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Literature Review Synthesis Report.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> CSIS Institute of Public Goods and Policies, Madrid, 2019.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Floridi, L. ‘Establishing the Rules for Building Trustworthy AI’, </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Nat Mach Intell</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> 1 (2019): 261–262.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Floridi, L., Cowls, J., Beltrametti, M. et al. AI4People—An Ethical Framework for a Good AI Society: Opportunities, Risks, Principles, and Recommendations. </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Minds &amp; Machines</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> 28, (2018): 689–707.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Jasanoff, S. </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>The Ethics of Invention</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>, New York: W. W. Norton &amp; Company, 2016.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Jobin, A., Ienca, M. &amp; Vayena, E. ‘The Global Landscape of AI Ethics Guidelines’, </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Nat Mach Intell</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> 1 (2019): 389–99.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Mattingly, C. and J. Throop. ‘The Anthropology of Ethics and Morality’, </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Annual Review of Anthropology</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> 47:1 (2018): 475–92.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>O’Nell, O. ‘Accountable Institutions, Trustworthy Cultures’, </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Hague J Rule Law</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> 9 (2017): 401–12.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Pels, P. ‘The Trickster’s Dilemma: Ethics and the Technologies of the Anthropological Self’ in M. Strathern (ed) </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Audit Cultures: Anthropological Studies in Accountability</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>, London: Routledge, 2000, pp. 147–84.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Pink, S. ‘Ethics in a Changing World: Embracing Uncertainty, Understanding Futures, and Making Responsible Interventions’ in xS. Pink, V. Fors, T. O’Dell (eds) </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Working in the Between: Theoretical Scholarship and Applied Practice.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> Oxford: Berghahn, 2017, pp. 29–51.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>——. ‘Trust, Ethics and Automation: Anticipatory Imaginaries in Everyday Life’ in Pink, S., Lupton, D., Berg, M. and Ruckenstein, M. (eds) </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Everyday Automation</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>, London: Routledge, 2022, 44–58.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Pink, S., Raats, K., Lindgren T., Osz, K. and Fors, V. ‘An Interventional Design Anthropology of Emerging Technologies’ in Hojer Bruun, M., Wahlberg, A., Brogaard Kristensen, D., Douglas-Jones, R.,  Hasse, C., Høyer, K., and Ross Winthereik, B. (eds) </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>The Handbook for the Anthropology of Technology</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>, London: Palgrave, 2021, pp. 183–200.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Stilgoe, J., T. Cohen, ‘Rejecting Acceptance: Learning from Public Dialogue on Self-Driving Vehicles’, </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Science and Public Policy</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>, 48.6 (2021): 849–59.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Strathern, M. (ed). </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Audit Cultures: Anthropological Studies in Accountability</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>, London: Routledge, 2000.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Wyatt, S. ‘Metaphors in Critical Internet and Digital Media Studies’, </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>New Media &amp; Society</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>, </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>23</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>.2 (2021): 406–16.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>

  </Story>
  
</Document>
