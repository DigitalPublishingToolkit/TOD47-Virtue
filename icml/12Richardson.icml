<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<?aid style="50" type="snippet" readerVersion="6.0" featureSet="513" product="8.0(370)" ?>
<?aid SnippetType="InCopyInterchange"?>
<Document DOMVersion="8.0" Self="pandoc_doc">
    <RootCharacterStyleGroup Self="pandoc_character_styles">
      <CharacterStyle Self="$ID/NormalCharacterStyle" Name="Default" />
      <CharacterStyle Self="CharacterStyle/" Name="">
        <Properties>
          <BasedOn type="object">$ID/NormalCharacterStyle</BasedOn>
        </Properties>
      </CharacterStyle>
      <CharacterStyle Self="CharacterStyle/Italic" Name="Italic" FontStyle="Italic">
        <Properties>
          <BasedOn type="object">$ID/NormalCharacterStyle</BasedOn>
        </Properties>
      </CharacterStyle> 
    </RootCharacterStyleGroup>
    <RootParagraphStyleGroup Self="pandoc_paragraph_styles">
      <ParagraphStyle Self="$ID/NormalParagraphStyle" Name="$ID/NormalParagraphStyle"
          SpaceBefore="6" SpaceAfter="6"> <!-- paragraph spacing -->
        <Properties>
          <TabList type="list">
            <ListItem type="record">
              <Alignment type="enumeration">LeftAlign</Alignment>
              <AlignmentCharacter type="string">.</AlignmentCharacter>
              <Leader type="string"></Leader>
              <Position type="unit">10</Position> <!-- first tab stop -->
            </ListItem>
          </TabList>
        </Properties>
      </ParagraphStyle>
      <ParagraphStyle Self="ParagraphStyle/Blockquote &gt; Paragraph" Name="Blockquote &gt; Paragraph" LeftIndent="10">
        <Properties>
          <BasedOn type="object">$ID/NormalParagraphStyle</BasedOn>
        </Properties>
      </ParagraphStyle>
      <ParagraphStyle Self="ParagraphStyle/Caption" Name="Caption" LeftIndent="0">
        <Properties>
          <BasedOn type="object">$ID/NormalParagraphStyle</BasedOn>
        </Properties>
      </ParagraphStyle>
      <ParagraphStyle Self="ParagraphStyle/Figure" Name="Figure" LeftIndent="0">
        <Properties>
          <BasedOn type="object">$ID/NormalParagraphStyle</BasedOn>
        </Properties>
      </ParagraphStyle>
      <ParagraphStyle Self="ParagraphStyle/Footnote &gt; Paragraph" Name="Footnote &gt; Paragraph" LeftIndent="0">
        <Properties>
          <BasedOn type="object">$ID/NormalParagraphStyle</BasedOn>
        </Properties>
      </ParagraphStyle>
      <ParagraphStyle Self="ParagraphStyle/Header1" Name="Header1" LeftIndent="0" PointSize="36">
        <Properties>
          <BasedOn type="object">$ID/NormalParagraphStyle</BasedOn>
        </Properties>
      </ParagraphStyle>
      <ParagraphStyle Self="ParagraphStyle/Header2" Name="Header2" LeftIndent="0" PointSize="30">
        <Properties>
          <BasedOn type="object">$ID/NormalParagraphStyle</BasedOn>
        </Properties>
      </ParagraphStyle>
      <ParagraphStyle Self="ParagraphStyle/Header3" Name="Header3" LeftIndent="0" PointSize="24">
        <Properties>
          <BasedOn type="object">$ID/NormalParagraphStyle</BasedOn>
        </Properties>
      </ParagraphStyle>
      <ParagraphStyle Self="ParagraphStyle/Paragraph" Name="Paragraph" LeftIndent="0">
        <Properties>
          <BasedOn type="object">$ID/NormalParagraphStyle</BasedOn>
        </Properties>
      </ParagraphStyle> 
    </RootParagraphStyleGroup>
    <RootTableStyleGroup Self="pandoc_table_styles">
      <TableStyle Self="TableStyle/Table" Name="Table" />
    </RootTableStyleGroup>
    <RootCellStyleGroup Self="pandoc_cell_styles">
      <CellStyle Self="CellStyle/Cell" AppliedParagraphStyle="ParagraphStyle/$ID/[No paragraph style]" Name="Cell" />
    </RootCellStyleGroup>
  <Story Self="pandoc_story"
      TrackChanges="false"
      StoryTitle=""
      AppliedTOCStyle="n"
      AppliedNamedGrid="n" >
    <StoryPreference OpticalMarginAlignment="true" OpticalMarginSize="12" />

<!-- body needs to be non-indented, otherwise code blocks are indented too far -->
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Header1">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Military Virtues and the Limits of ‘Ethics’ in AI Research</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Header3">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Michael Richardson</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>War trades on virtue. The virtue of warriors, of just causes, of doing what must be done in the face of adversity to sustain nation or religion. War’s virtue extends to antiquity, at least in the West, but its modern articulation bears distinct characteristics. Virtuous war is now technological war, war applied with precision, information, rationality, and proportionality bequeathed by technological revolutions of logistics, science, and computation. In the shift currently underway to autonomous weapons systems (AWS) and the incorporation of artificial intelligence (AI) more generally into warfare, virtue functions to sell publics and institutions on the necessity of ever more complex, more codified, and more inscrutable emergent technologies. Virtue does not simply flow from AWS and military AI, but is imbued in them by the incorporation of laws and ethics within the systems themselves. Or so the story goes. Just as the virtues of virtuality contributed to the obscuring of the violence of America’s forever wars in the aftermath of 9/11, so too do the embrace and promotion of the virtues of autonomous systems risk occluding the reproduction and intensification of existing injuries and injustices, as well as the creation of new forms of violence and oppression.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>While Big Tech’s forays into U.S. military contracts tend to attract controversy—think Google and the outrage over its work to apply TensorFlow algorithms to drone image processing as part of the Department of Defense’s (DoD) Project Maven initiative—interdependencies between militaries and private and civil institutions are equally pernicious in the thriving ecologies of start-ups, research translation hubs, defence funding programs, government initiatives, cash-strapped universities, and grant-hungry academics that can be found across the globe. In these economies of virtue, ‘ethics’ serve not only to facilitate mutually beneficial collaborations by cloaking military violence but also as potential commodities, able to be coded into the very technologies at hand.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>Thao Phan et al., ‘‘Economies of Virtue: The Circulation of ‘Ethics’ in Big Tech,’’ </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Science as Culture</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content> 31.1 (2021): 121–35.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> Defence researchers and companies can not only </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>be</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> virtuous, but also can </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>make</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> war virtuous too. In this chapter, I examine the emerging military technology industry in Australia and its relation to academia to argue that military economies of virtue operate in ways that are similar to and different from those at work at the wider nexus of the tech sector and AI research in the academy.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Militaries are well behind the private sector in AI and big data development and expertise. This reality is accelerating collaborative, industry-led processes that mimic aspects of the Silicon Valley model of agile development, as the head of Pentagon’s Algorithmic Warfare Cross-Functional Warfare Team (AWCFT) admitted on its formation in 2017.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>Department of Defence, ‘Memorandum for the Establishment of an Algorithmic Warfare Cross-Functional Team (Project Maven),’ 26 April 2017, https://www.govexec.com/media/gbc/docs/pdfs_edit/establishment_of_the_awcft_project_maven.pdf.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> This move-fast-and-break-things approach could have serious repercussions given the life and death situations in which military technology is often applied. But militaries are not only valuable clients for Big Tech, but also increasingly important sources of funding for academic research. In the context of military AI, ‘ethics’ possesses an economic function that frames, facilitates, and feeds engagements between industry, academia, and military institutions. Military technologies and especially weapons systems are often framed by distinct ethics discourses, which emerge from a melange of the laws of armed conflict, international humanitarian law, specific and predefined rules of engagement, and—more nebulously—a warrior ethos. Militaries, including the Australian Defence Force (ADF), tend to see ethics as instrumental and principally related to conduct on and off the battlefield by individual soldiers, rather than enmeshed with larger questions of justice or societal obligation. Ethics are typically posed as both values to hold and problems to solve. When this approach encounters military AI, the limits of ‘ethics’ as a framework for reducing harm become clear: ethics are already subordinated to martial violence in that they are always concerned with enabling its infliction.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Header2">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Military Virtues</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>According to international relations scholar James Der Derian, the growing centrality of computation to warfare that began in the Cold War and accelerated dramatically in its aftermath signals the emergence of a new mode of armed conflict led by the United States. ‘At the heart of virtuous war,’ writes Der Derian, ‘is the technical capability and ethical imperative to threaten and, if necessary, actualise violence from a distance—</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>with no or minimal casualties</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>.’</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>James Der Derian, </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Virtuous War: Mapping the Military-Industrial-Media-Entertainment Network</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>, 2nd edn., New York: Routledge, 2009, p. xxxi.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> Of course, virtuous war has not eliminated killing, nor the killing of civilians, as the use of drones and autonomous systems by the United States and Israel readily attests. Nor does virtuous war stop at violence itself: war in Der Derian’s conception is also virtual, in the sense that it depends more and more upon information and abstraction. While the attempt to capture both ‘virtue’ and ‘virtual’ in his coining of a new form of warfare is somewhat murky, his analysis nonetheless points to the close relation between emergent forms of warfare dependent on simulation, modelling, computation, automation, and autonomy and the discursive refiguring of warfare that legitimises its centrality. As Der Derian points out, virtuous war is produced by and in turn sustains an amorphous array of agencies, actors, and institutions that he calls the military-industrial-media-entertainment network, or MIME-NET.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>Der Derian, </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Virtuous War</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>, p. 83.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> Hovering close at hand is the university and its researchers.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Tight ties between militaries and academia are far from new, both in the U.S. and elsewhere. During the Cold War, the Department of Defense (DoD), Central Intelligence Agency (CIA), and the Defence Advanced Research Projects Agency (DARPA) began directly funding research in the U.S. and around the world across a host of disciplines, from nuclear physics to psychology to medicine to anthropology. DARPA also funded the Strategic Computing Initiative, which pumped over USD$1bn into advanced computation and artificial intelligence from 1983 to 1993. But military funding was also critical to the very emergence of computation and cybernetics, which laid the conceptual and mathematical foundation for contemporary techniques of machine learning that are often packaged and promoted as ‘Artificial Intelligence,’</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>Orit Halpern, </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Beautiful Data: A History of Vision and Reason since 1945</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>, Durham: Duke University Press, 2015.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> even if they largely depend on human labour.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>Jathan Sadowski, ‘Potemkin AI,’ </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Real Life</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>, 6 August 2018, https://reallifemag.com/potemkin-ai/.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> Whether applied to military or civilian contexts, contemporary techniques of machine learning depend on compute power that often far exceeds the capacity of university labs, even when resources are pooled between institutions. This has contributed to what Meredith Whittaker calls the ‘capture’ of AI research by Big Tech, in which researchers become dependent on access to platforms run by Amazon, Google, and Microsoft, and so tend to undertake research that fits within AI paradigms that reproduce the existing infrastructures as beneficial and necessary.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>Meredith Whittaker, ‘The Steep Cost of Capture,’ </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Interactions</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content> 28.6 (2021): 50–55.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> This dependence operates in the shadow of recurring controversies surrounding the social, cultural, and political impacts of Big Tech (and particularly Facebook, Google, and Amazon).</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>These controversies in turn intensify the need for ‘economies of virtue’ in which ‘virtue and ethics are the primary objects that are produced and circulated by groups inside Big Tech—through the establishment of, for example, ethics boards and working groups—and also outside, from universities, research institutes, consultancies, and other allied industries.’</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>Phan et al., ‘Economies of Virtue,’ p. 2.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> As the editors of this volume point out in their recent provocation on the subject, this economy arises in a context of a growing crisis in public funding of Western universities and of research in particular, which has intensified dependencies such as that of AI research on Big Tech dollars. Examination of these relations in a commercial setting is critical, but military, national security, and intelligence entanglements cannot be excised from the equation or treated as a minor case study. While the critical scholarship on the incorporation of AI into war and national security continues to grow, the institutional role of universities and funding mechanisms in that process demands more attention.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>See, for example, Louise Amoore, ‘Algorithmic War: Everyday Geographies of the War on Terror,’ </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Antipode</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content> 41, no. 1 (2009): 49–69; Louise Amoore, </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Cloud Ethics: Algorithms and the Attributes of Ourselves and Others</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content> Durham: Duke University Press, 2020; Rocco Bellanova, Katja Lindskov Jacobsen, and Linda Monsees, ‘Taking the Trouble: Science, Technology and Security Studies’, </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Critical Studies on Security</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content> 8.2 (2020): 87–100; Jeremy Packer and Joshua Reeves, </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Killer Apps: War, Media, Machine</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>, Durham: Duke University Press, 2020; Lucy Suchman, ‘Algorithmic Warfare and the Reinvention of Accuracy,’ </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Critical Studies on Security</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content> 8.2 (2020): 1–13; Lucy Suchman, Karolina Follis, and Jutta Weber, ‘Tracking and Targeting: Sociotechnologies of (In)Security’, </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Science, Technology, &amp; Human Values</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content> 42.6 (2017): 983–1002.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Universities, as Alison Howell persuasively argues, have not been recently ‘militarised’ but have always been institutions produced by martial politics and in service of martial ends.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>Alison Howell, ‘Forget “Militarization”: Race, Disability and the “Martial Politics” of the Police and of the University’, </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>International Feminist Journal of Politics</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content> 20.2 (2018): 117–36.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> As noted above, the internet more generally and AI itself owed and continue to owe much to military funding and objectives, both in direct and indirect ways. Today in the United States, one of the leading proponents of military AI development and a cheerleader for an international AI arms race is former Google CEO Eric Schmidt, now the head of Defence Technology Innovation Board. For Schmidt and his fellow travellers, military AI applications are always already virtuous precisely because they secure the state against threat and strengthen its standing in the global arena. All this could be understood as an attempt to securitize AI itself, such that much of the work that happens in this sphere enters into a domain outside ordinary politics and, in doing so, operates in the exceptional space of security.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>Barry Buzan, Ole Wæver, and Jaap de Wilde, </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Security: A New Framework for Analysis</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>, Boulder: Lynne Reiner Publishers, 1998.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> The task, then, is to examine </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>how</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> militaries participate in economies of virtue in AI research, because the way they conceive and commodify ethics is often different from civilian actors.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>This chapter takes up this question of how militaries participate in economies of virtue by examining the Australian context, rather than the American. This examination is instructive because Australia is in the early days of a deliberate strategic effort to accelerate its military industries, both to provide homegrown technology and to produce a new export sector. In military spending terms, Australia is a moderate player, committing $44.619 bn in 2021–22, or 2.09 percent of GDP and 1.4 percent of total global defence spending (compared to 39 percent by the US and 13 percent by China), but with those figures set to grow under commitments made by the Morrison government, including at least $70bn for nuclear powered submarines under the new tripartite AUKUS arrangement.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>Science Department of Industry, ‘Growth opportunities,’ Text, Department of Industry, Science, Energy and Resources, Department of Industry, Science, Energy and Resources, 30 March 2021, https://www.industry.gov.au/data-and-publications/defence-national-manufacturing-priority-road-map/growth-opportunities; Ministers for the Department of Industry, Science, Energy and Resources, ‘Action Plan to Supercharge Research Commercialisation,’ 2 February 2 2022, https://www.minister.industry.gov.au/ministers/taylor/media-releases/action-plan-supercharge-research-commercialisation; Tory Shepherd, ‘Australia’s Aukus Nuclear Submarines Could Cost as Much as $171bn, Report Finds,’ </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Guardian</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>, 13 December 2021, sec. World news, https://www.theguardian.com/world/2021/dec/14/australias-aukus-nuclear-submarines-estimated-to-cost-at-least-70bn.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> In export terms, Australia’s defence industry is barely a player at all, with just $5.5bn in exports in 2019–20. But that figure is up from $1.5bn in 2017–18, the direct result of a range of government initiatives, targeted investment strategies, academic research funding programs, and knowledge transfer hubs. Together, these aim to hothouse military technology start-ups by echoing the public–private partnerships so beloved by neoliberal infrastructure builders. To show how military ethics functions within economies of virtue, this essay argues that three critical dynamics around ‘ethics’ are shaping the emerging military technology industry in Australia and its relation to academia. I begin by examining how ethics function as a martial commodity in military technology start-ups, using the case study of Cyborg Dynamics Engineering and its Athena AI platform. Next, I turn to the discursive function that ethics serves in the growing defence industries in Australia by examining the role of new Defence Collaborative Research Centre (DCRC) initiatives, with a focus on the Trusted Autonomous Systems DCRC in Brisbane, Queensland. Third, I make the deliberately provocative proposal that ‘ethics’ facilitates engagement with universities, with research funding as a central factor, materialised through centres, networks, symposiums, and workshops. In this context, ethics serves as a keyword of the defence-academia-industrial complex. In closing, I argue that martial conceptions of ethics and virtue are a distinct yet critical component of economies of virtue that require further research and sustained critical attention.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Header2">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Military Ethics as Code and Commodity</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Ethics, laws, and codes abound in military context, from the Laws of Armed Conflict (LOAC) to Codes of Conduct to more amorphous yet morally forceful concepts such as the warrior ethos. States themselves are constrained—in theory, if not always in practice—by international laws, which determine both the instances in which war may be deemed just and which protect the rights of civilians within conflict. When soldiers go to war, ‘they are bound by a series of ethical principles that proscribe particular actions and forbid others.’</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>Matthew Beard, ‘Beyond Tallinn: The Code of the Cyberwarrior?’ in </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Binary Bullets: The Ethics of Cyberwarfare</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>, Fritz Allhoff, Adam Henschke, and Bradley Jay Strawser (eds), New York: Oxford University Press, 2016, p. 139.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> Virtuous conduct might not be set out in such principles, but instead be culturally produced and maintained within particularly armed services or units. We might think of virtue as more closely tied with morality—with good character—whereas ethics concerns behaviour and the limits of what is allowable in certain circumstances. Both military ethics and virtue are not immutable but rather have developed substantially over time, often in association with the rise of new forms of warfare such as the proliferation of airpower in the twentieth century. Conflated with codes and laws governing conduct, ethics tend to be narrowly conceived in military contexts, whereas soldiers can feel a more complex and intense relation to the warrior ethos.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>With the emergence of technologies for finding, selecting, targeting, and killing, the potential to code ethics into computational systems has proven alluring to military leaders. As Christian Enemark has observed, the rise of drone warfare changes the ethical calculus of war for states, as the lack of exposure of soldiers to risk and the arguable reduction in civilian casualties promises to produce more ethical warfare through technological advancement.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>Christian Enemark, </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Armed Drones and the Ethics of War: Military Virtue in a Post-Heroic Age</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>, London: Routledge, 2014.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> Autonomous weapons systems promise to further remove the fallible and flawed human decision-making from the equation, transforming the codes of law, ethics, and conduct into computational decision-trees that can be applied in measured, flexible, and reliable fashion by autonomous systems, whether ‘intelligent’ or not. Here, questions of ethics often turn on the relation of a human operator to the kill decision—in-the-loop, on the loop, or off-the-loop—or, more fundamentally, on a moral insistence that killing in war should always be a human decision.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>Elke Schwarz, </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Death Machines: The Ethics of Violent Technologies</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>, Manchester: Manchester University Press, 2018; Noel Sharkey, ‘Automating Warfare: Lessons Learned from the Drones’, </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Journal of Law, Information and Science</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content> 21.2 (2011): 140–54.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> If contemporary developments in AWS and the failure of the 2021 Convention on Conventional Weapons (CCW) to regulate their use is an indication, the stance that views automated killing as morally reprehensible is in grave trouble. There are huge philosophical and practical implications of the increasing autonomy of warfare, whether in terms of the material operation of AWS or in relation to the algorithmic processes and thinking that underpin them, which threaten to overwhelm the very possibility of law containing martial violence that preempts and outpaces human capacities to think and decide.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>See, for example, Max Liljefors, Gregor Noll, and Daniel Steuer (eds), </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>War and Algorithm</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>,(London; New York: Rowman &amp; Littlefield International, 2019.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>But while scholars, activists, and publics around the world remain apprehensive about the dangers of ‘killer robots,’ the question of whether machines will decide on lethal actions has largely been decided in practice. Here the distinct nature of military ethics actually facilitates the emergence of ever-more autonomous technologies. Even if they are embedded in a detailed social, institutional, historical, and philosophical context (see, for example, the Australian Defence Force 2021 Military Ethics doctrine), military ethics still need to be operationalized for the battlefield so that soldiers can make swift life and death decisions. Understood as codes, ethics becomes codable—capable of being translated into computational form, taught to intelligent systems, and applied in specific contexts. As Elke Schwartz observes, this ‘logic of an ethics module is reliant on a conception of ethics as codifable, as ascertainable, and as producing clear, secure and, ideally, certain outcomes.’</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>Schwartz, </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Death Machines</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>, p. 16.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> Coded ethics becomes a commodity, central to the sales pitch of start-ups and all too appealing to the officers tasked with overseeing the development and procurement of algorithmic and autonomous technologies.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>Elke Schwarz, ‘Silicon Valley Goes to War: Artificial Intelligence, Weapons Systems, and Moral Agency’, </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Philosophy Today</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content> 65.3 (2021): 549–69.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>The Australian start-up Cyborg Dynamics Engineering offers a telling case study. Its flagship product is the Athena AI, a platform for weapons targeting and battlefield analytics. As the company website states, ‘Athena AI is one of the only vision-based AI systems on the market that combines AI computer vision, AI enabled decision support and display of the AI information in a user interface.’ While not itself an autonomous weapons system, Athena AI is designed to augment human targeting and, crucially, to provide object recognition and ethical and legal evaluation tools. In public presentations and on the company website, Cyborg Dynamics touts these ethical capabilities as critical distinctions. In a short reflective academic article by the founder of Cyborg Dynamics and collaborators at or affiliated with the Trusted Autonomous Systems Defence Collaborative Research Centre describe the technology as aiming to ‘augment human ethical and legal decision-making on the battlefield by reducing the “fog of war,” and improving abidance with international humanitarian law.’</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>Tara Roberson et al., ‘A Method for Ethical AI in Defence: A Case Study on Developing Trustworthy Autonomous Systems’, </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Journal of Responsible Technology</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content> 11 (2022): 1.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> While that article demonstrates the iterative and responsive approach to ethics undertaken in the development of Athena AI, an extended quote from the company website reveals how ethics becomes a value-add in marketing rhetoric:</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Blockquote &gt; Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Athena AI is one of the only trusted AI products, having worked with International Weapons Review, military legal officers and military ethicists to help define a suitable data assurance and test methodology for AI vision and decision support certification. Our inbuilt decision support tools have legal and rules of engagement considerations where applicable.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Positioned first in a list of advantages for the system, this encoding of ethics through the tying of LOAC, rules of engagement, and other such codes to specific combat instances positions Athena AI as an improvement upon the status quo. Familiar components of an economy of virtue are evident too, through the participation of the boutique legal consultancy International Weapons Review (IWR). As with the tech-critical entities caught up in the economies of virtue described by this volume’s editors, organisations like IWR are not ‘the problem’ per se—in IWR’s case, the firm is run by experienced military lawyers with strong scholarly standing—but are nonetheless part of the varied, evolving terrain of military ethics economies.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>Phan et al., ‘Economies of Virtue’, p. 10.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> What goes unsaid in Cyborg Dynamics’ rhetoric is that the various detection and classification functions of the platform—enabled, according to the company website, by multi-staged neural networks—are implicitly legitimated and amplified by the legal architecture that the system claims to provide. From a political standpoint, ‘ethics’ here serves to lower the intensity of political engagement by transforming concerns over military technologies into the technocratic domain where computation meets law. But in industry, ethics functions to boost the commodity value of the system: the system itself is virtuous because it is already encoded with ethics and thus it promises to make the armed services that deploy it more rigorous in their adherence to ethical codes.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Header2">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Ethics and the Infrastructures of Research Translation</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Companies like Cyborg Dynamics are part of a burgeoning ecology of small and medium enterprises (SMEs) within the Australian defence industries. Under the conservative leadership of former prime minister Malcolm Turnbull, defence industry growth was deemed a crucial national priority, both to reduce dependencies on foreign imports and to generate jobs. However, the Australian Defence Forces are not large enough purchasers to sustain a viable domestic defence industry. As the Australian Department of Defence’s Defence Export Strategy states, ‘[n]ew markets and opportunities to diversify are required to help unlock the full potential of the Australian defence industry to grow, innovate and support Defence’s future needs.’</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>Australian Department of Defence, </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Defence Export Strategy</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>, Commonwealth of Australia, 2018.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> Via the 2020 Defence Strategic Update, then prime minister Scott Morrison committed AUD$270bn over the next decade to defence spending, aimed at increasing and updating Australia’s military capacity and with significant opportunities for industry and workers, with various skill training programs designed to support naval shipbuilding and other defence priorities.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Within this push, AI and other high-tech systems play an important role in positioning the Australian defence industry as innovative, forward-looking, and poised to contribute to the priorities of its allies. The flagship project in this regard is the Boeing Airpower Teaming System (ATS), described by the American defence giant on its website as a ‘smart, uncrewed force multiplier.’ Developed in collaboration with a number of Australian SMEs, the project—nicknamed ‘Loyal Wingman’—aims to develop a fast, attacking drone aircraft capable of operating in support of human pilots engaged in dangerous missions, allowing pilots to remain at a safe distance from high intensity conflict zones or providing additional firepower in the event of an aerial dogfight. As such, the ATS must operate with significant autonomy for navigation, guidance, and targeting, which in turn demands considerable expertise and opens up major ethical questions about the use of force.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Situations like this are where research translation institutions such as the Trusted Autonomous Systems Defence Cooperative Research Centre (TAS) play a critical role, both in facilitating the involvement of Australian enterprises and in foregrounding ethics in the design and promotion of autonomous systems in defence. In operation since 1990, Cooperative Research Centres (CRCs) are an Australian government initiative designed to connect academic research with ‘industry-led’ projects, with funding typically awarded in the tens of millions and over several years to a partnership involving at least one industry and one university partner. A number of CRCs have some crossover with national security, such as the Data to Decisions (D2D) and Cyber Security CRCs, but are more oriented to civilian concerns or, if securitized, more likely to be concerned with defence-adjacent activities like law enforcement and signals intelligence. The Defence Cooperative Research Centre is a more recent subset, funded by the Next Generation Technologies Fund which has been allocated $730 million from 2016–17 to 2025–26 to invest ‘in forward-looking game-changing capabilities aligned with Defence priorities,’ according to a Department of Industry, Innovation and Science fact sheet. As the first Defence Cooperative Research Centre, TAS has received considerable resourcing and funding from the Australian government as well as the Queensland state government, which is also the only state to have a drone industry strategy. While the Boeing ATS project has garnered by far the most media attention, the bread and butter of TAS is smaller projects with SMEs, many based in Queensland. But the CRC is also engaged in its own initiatives to develop assurance and ethical frameworks for autonomous systems in defence.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>A core component of this is their ‘Ethics and Law of Trusted Autonomous Systems’ program, conducted in conjunction with University of Queensland’s Future of War and Law Research Group. As the TAS website states, their ‘Ethics Uplift Program engages diverse stakeholders to provide evidence-based and practical risk management for ethical and deployable AI in Defence.’ As in the economies of virtue that surround Big Tech, the purpose of this program is not to question or critique the foundational grounds of defence industries but to ‘produce ethics, legal, safety and accountability frameworks for use of the electromagnetic spectrum, robotics, autonomous systems and artificial intelligence deployed within human-machine (HUM-T).’ Led by TAS Chief Scientist Dr Kate Devitt, an ethicist by training with a track record of robust critical scholarship on data and ethics, it can certainly be argued that such initiatives should be understood in favourable terms as doing crucial work to ensure that ethics are built into defence industry projects and products from the beginning. An absence of such frameworks would not stall initiatives, such an interpretation would argue, but only mean that they go ahead with ethics less central to their conception. There is merit in such claims, and TAS has also been able to leverage its close relationship with the ADF to co-author ‘A Method for Ethical AI in Defence,’ a technical report of the Defence Science &amp; Technology Group (DSTG), a military entity that funds, facilitates, and prototypes new technology initiatives.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>In the context of TAS, we need to understand ‘ethics’ as operating in at least two modalities. The first is that outlined above, in which TAS plays an infrastructural role in ensuring that ethical considerations are foundational to military technologies developed in Australia. The second modality sees these ethics initiatives as functioning discursively to legitimate defence industries within academia and with wider publics. In this sense, the Trusted Autonomous Systems Defence Cooperative Research Centre can be understood as a kind of ethics clearing house, connecting legal, philosophical and other humanities research with military institutions, practitioners, and industry, with a particular emphasis on start-ups. Doing so enables ‘ethics’ to be ‘built in’ to AI and autonomous systems, with difficult questions around the ethics of such technologies in the martial context pursued in conjunction with or adjacent to their development. As the extensive list of TAS-supported academic publications attests, TAS and its affiliated researchers take theoretical and practical questions of ethics seriously.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>See, for example, S. Kate Devitt, ‘Normative Epistemology for Lethal Autonomous Weapons Systems’ in Galliott, Jai, MacIntosh, Duncan and Ohlin, Jens David (eds) </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Lethal Autonomous Weapons: Re-Examining the Law and Ethics of Robotic Warfare</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>, Oxford: Oxford University Press, 2021, pp. 237–58; S. Kate Devitt et al., ‘Developing a Trusted Human-AI Network for Humanitarian Benefit,’ (preprint); Jai Galliott, Duncan MacIntosh, and Jens David Ohlin (eds), </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Lethal Autonomous Weapons: Re-Examining the Law and Ethics of Robotic Warfare</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>, Ethics, National Security, and the Rule of Law, Oxford; New York: Oxford University Press, 2021; Eve Massingham, ‘Automation of the Spectrum, Automation and the Spectrum: Legal Challenges When Optimising Spectrum Use for Military Operations’, </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Law, Technology and Humans</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content> 3. 2 (2021): 91–106; Tara Roberson et al., ‘A Method for Ethical AI in Defence: A Case Study on Developing Trustworthy Autonomous Systems’.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> Nor is TAS funded to generate large scale critique of military operations or military spending as such, but rather to develop home-grown defence industries that conform to Defence values and ethics. As is often the case in innovation contexts, the presence of social scientists and ethicists constitutes a kind of care work, which here becomes care for the virtues of the nation and its Defence endeavours.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>Ana Viseu, ‘Caring for Nanotechnology? Being an Integrated Social Scientist,’ </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Social Studies of Science</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content> 45.5 (2015): 642–64.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> As such, TAS can be understood as a vital cog in Australia’s economies of military virtue. This is not to dismiss out of hand recent initiatives to deploy AI to identify cultural assets for Western Yalanji peoples, help preserve Cape York languages, or develop an autonomous marine vessel code of practice, but rather to recognise that all such endeavours are bound up with the production and commodification of virtue.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Header2">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Virtue, Academia, and ‘Ethics’ in Research Funding</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Within the Australian academy, research funding has been placed under increasing pressure over the last two decades, and particularly under the conservative government in power since 2013. In 2014, competitive grant funding by the Australian Research Council (ARC) stood at $886m; eight years later in 2022, it was $815m. As a researcher fortunate enough to receive ARC funding, I can attest to the luck involved in having such grants awarded—especially in the humanities. A growing government emphasis on impact, engagement with industry, and especially research commercialisation has pushed funding more towards applied and away from basic research. In 2022, the Morrison Government announced a $2.2bn fund dubbed ‘Australia’s Economic Accelerator, of which $1.6bn was earmarked for research that can be ‘commercialised’ in alignment with National Manufactory Priorities, which include ‘defence and space’. Within this context, ‘ethics’ functions as a keyword for the role of humanities and social science (HASS) research, particularly in the military sphere, as it enables claims of value within research spaces otherwise focused on technological development. With defence and national security framed as virtuous endeavours, ethics also provides a common language with computer science, engineering, psychology, and other disciplines more closely aligned historically to defence research. Humanities research into communication, for example, can help do information warfare the right way or assist in the development of ‘ethical’ autonomous battlefield systems.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Measuring the full extent of the impact of military funding on Australian academic research is exceedingly difficult, even in general terms. At the most prosaic level, there is the problem of classifying so-called ‘dual use’ research, such as when the US Department of Defence funds medical research. But there are also other challenges. How do you define and delimit defence vs national security vs intelligence funding? Can initiatives funded by the office of the prime minister, by cabinet, or even by premiers be identified when explicit budgets are not available? What about top secret initiatives? Or disparities between budgeted amounts and actual expenditure? While Australian government spending does entail certain degrees of transparency and accountability, defence funding can be much more difficult to trace due to the scale, secrecy, complexity, and overall opacity of the national security elements of the state. That said, in Australia much of the more overt—and substantive—defence funding flows from the Defence Science &amp; Technology Group (DSTG), an entity within Defence that seeks to coordinate research priorities and provide an interface for both academia and industry. Collaborative initiatives such as the Operations Research Network (ORNet) directly address defence operations (command and control, force design, operational planning, etc), while the Science Partnerships (DSP) program provides a common framework for working with defence and counts every public university in the country as a member. At the state level, organisations such as the Defence Innovation Network (in NSW and the ACT) or the Defence Science Institute (VIC) work closely with DTSG to link up university researchers with SMEs around priority problems. Academia thus engages with defence via an evolving institutional infrastructure, which works to couch defence priorities in the language of science and provide fora through which Defence personnel can engage directly with researchers across a range of fields.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Virtue and ethics easily become the discursive and affective enablers of increasingly militarised academic research. To take one example, the influential Australian Strategic Policy Institute (ASPI) has publicly advocated for much closer ties between academia and defence with a strong focus on the virtues of national security. While ASPI is constituted as a nonpartisan think tank, its agenda is firmly in line with an expansive national security state and, beyond Australia’s borders, with allied nations through the Five Eyes intelligence partnership with the U.S., U.K., Canada, and New Zealand. In a series of blogs, opinion pieces, and reports, ASPI chief executive Peter Jennings and former chief defence scientist Robert Clark have called for a ‘Five Eyes friendly’ university sector and the creation of an Australian DARPA, the Pentagon’s famous Defence Advanced Research Projects Agency, responsible for innovations ranging from the early internet to retrofitting Hellfire missiles to Predator drones after 9/11.</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle" Position="Superscript">
    <Footnote>
      <ParagraphStyleRange>
        <CharacterStyleRange>
          <Content><?ACE 4?></Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
      <ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Footnote &gt; Paragraph">
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>	</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>Robert Clark and Peter Jennings, ‘An Australian DARPA to Turbocharge Universities’ National Security Research: Securely Managed Defence-Funded Research Partnerships in Five-Eyes Universities,’ </Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
          <Content>Australian Strategic Policy Institute blog</Content>
        </CharacterStyleRange>
        <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
          <Content>, 14 July 2021, https://www.aspi.org.au/report/australian-darpa-turbocharge-universities-national-security-research-securely-managed.</Content>
        </CharacterStyleRange>
      </ParagraphStyleRange>
    </Footnote>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Universities are often eager hosts for new defence initiatives. My own institution, which runs the Australian Defence Force Academy in Canberra, has the UNSW Defence Research Institute, the webpage of which consists of gritty war-tech images and very little actual information, including none at all about who is involved with the institute. More often, though, defence initiatives are highly touted and full of information. Our Trusted Autonomy research group and Institute for Cyber Security, for example, are widely touted and active entities within the university, and UNSW is well represented in the Cyber Security CRC launched in 2018 with $50m in government funding. Some of the scholars involved in such initiatives are colleagues that I know and respect; so again, my point is not to cast stones. After all, even if my own research is not defence-funded, my university receives significant income from the ADF and, like almost all Australian universities, relies on state funding for both teaching and research. What’s important is that on-the-ground infrastructure such as this is critical to meet the kinds of cross-disciplinary problems posed by contemporary defence challenges, as articulated most clearly in the Australian context by the DSTG (Defence Science, Technology and Research Group) STaR shots which include topics such as Agile Command and Control, Disruptive Weapons Effects, and Information Warfare. This last is one area in which HASS researchers on automation and AI are particularly appealing, as attested to by the invitations for involvement in bids that I’ve received from my own faculty. Despite being a humanities researcher critical of military technology and militarization more generally, I often find myself in strange circumstances—workshops, symposiums, and discussion groups with defence-funded researchers or even defence personnel. For me, these are valuable opportunities to see inside the system, and understand its motivations and logics. My engagements with the Trusted Autonomous Systems CRC, for example, have been deeply informative, not least for the degree of insight they offer into the nuanced and even critical work going on adjacent to and inside militaries.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>The risk, however, is that in such contexts, ‘ethics’ becomes something that HASS researchers can contribute to grant bids, while virtue operates in the framing of such research as a national necessity that can save lives and secure prosperous and safe futures. The slippery nature of ‘ethics’ within these economies of virtues means that it can simultaneously signify both the codable rules developed by computer scientists and the processes, procedures, and fora produced by legal scholars, philosophers, and communications researchers, to name a few. Researchers who might otherwise be squeamish about doing ‘defence work’ can thus allow ‘ethics’ to insulate them from the kinetic operations and lethal violence that are the animating ethos of militaries around the world, Australia included. This in turn serves the interests of industry and defence, as it produces buffers of virtue that cloud the brutality at hand. ‘Ethics’ can thus be understood as a kind of floating signifier, a malleable referent that attaches itself to a host of situations and can readily be marshalled for martial ends.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Header2">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Conclusion</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>This nexus between the academy, defence, and industry should come as no surprise: universities have always been martial institutions, bent to martial ends and imbued with a martial politics. Universities are, after all, institutions of empire and colony even more than they are sites of learning, knowledge-making, and dissent. Yet the forms that this martial nature takes change with the times, with technology, and with ideological and economic sensibilities. In this chapter, I have argued that in the convergence of the military, the university, and industry on AI and autonomous technologies, a distinct form of economy can be detected, in which ‘ethics’ functions as commodity and currency dependent on context and ‘virtue’ draws heavily on military and statist values. In the sketch I have attempted here of an evolving Australian industry centred on new military technologies, ‘ethics’ greases the wheels of collaboration, cloaks the violent purposes of defence, and yet is always reducible in practice to a narrow and codable set of prescriptions, drawn from a predefined body of laws and conventions regarding armed conflict, weapons, and human rights. A shallow ‘ethics’ is nothing new, of course, but the crucial role it plays in the Australian context matters. Mapping and analysing this confluence of AI research, industry and application is a critical task because it operates according to a different logic and economy of funding than is the norm within tech support for academic research on AI and big data. This military formation of ‘ethics’ has the potential to metastasize into other contexts, particularly as cash-starved universities look to one of the only remaining well-funded institutions in Australian public life.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>To ask the famous question: what is to be done? The growing enmeshment of Big Tech in the American military establishment is hardly surprising, given the history of technology translation between Silicon Valley and DoD, but it has not been smooth. The 2018 Google Walkouts, sparked in part by the company’s involvement in Project Maven, indicates one potential fault line. High-skilled tech workers are more mobile than most, with high demand for their skills and so possess more leverage than individuals in most industries. But despite the high profile of the Walkouts and Google’s very public backdown on Project Maven, the fundamental relationship between tech and militarism has not changed substantially. When TAS was announced as an initiative at QUT, students launched a #booksnotbombs campaign (Figure 1) that focused on the inclusion of military giants BAE and Thales within the CRC funding model. While the campaign didn’t succeed, it and the Walkouts do suggest the necessity of collective responses within academia and tech to the growing influence of military dollars in both domains. For critical academics working in this space, one vital step is to follow the money—not by accessing military funding, but by mapping its movement through the university and para-academic system. Conducting such a forensic exercise would no doubt demand collective labour, as well as the formation of new networks of knowledge. Undertaking that project would not, of course, undo or even slow the operation of this particular economy of virtue. But it would expose the scale of the problem and move from the mix of general claims and specific instances articulated here into a more robust critique of how virtue operates at the nexus of militaries, academic, and AI research.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Figure">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Rectangle Self="uec" StrokeWeight="0" ItemTransform="1.00000 0 0 1.00000 150.00000 -112.00000">
      <Properties>
        <PathGeometry>
          <GeometryPathType PathOpen="false">
            <PathPointArray>
              <PathPointType Anchor="-150.00000 -112.00000" LeftDirection="-150.00000 -112.00000" RightDirection="-150.00000 -112.00000" />
              <PathPointType Anchor="-150.00000 112.00000" LeftDirection="-150.00000 112.00000" RightDirection="-150.00000 112.00000" />
              <PathPointType Anchor="150.00000 112.00000" LeftDirection="150.00000 112.00000" RightDirection="150.00000 112.00000" />
              <PathPointType Anchor="150.00000 -112.00000" LeftDirection="150.00000 -112.00000" RightDirection="150.00000 -112.00000" />
            </PathPointArray>
          </GeometryPathType>
        </PathGeometry>
      </Properties>
      <Image Self="ue6" ItemTransform="1.00000 0 0 1.00000 -150.00000 -112.00000">
        <Properties>
          <Profile type="string">
            $ID/Embedded
          </Profile>
        </Properties>
        <Link Self="ueb" LinkResourceURI="file:imgs/12.1.jpg" />
      </Image>
    </Rectangle>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Caption">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Fig 1: Banner from the Disarm QUT campaign. Image credit: Monique Mann.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Header2">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Acknowledgments</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>In addition to the editors and reviewers who provided astute guidance on this piece, I am deeply grateful to Dr Kate Devitt, who offered detailed, unflinching, and constructive feedback on an earlier version. Kate’s willingness to engage with an essay critical of TAS is testament to her own ethical rigour and generosity of thought but should not be read as an endorsement of its arguments. All errors that remain are my own.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Header2">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Funding Disclosure</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>This research was funded by ARC DECRA DE190100486, an Australian government initiative. It was also supported by the University of New South Wales, which is a member of the Defence Science Program and institutional home of the Australian Defence Force Academy.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Header2">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>References</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Amoore, Louise. ‘Algorithmic War: Everyday Geographies of the War on Terror’, </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Antipode</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> 41.1 (2009): 49–69.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Amoore, Louise. </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Cloud Ethics: Algorithms and the Attributes of Ourselves and Others</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>. Durham: Duke University Press, 2020.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Australian Defence Force. </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>ADF Philosophical Doctrine—Military Ethics. Australian Defence Force</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>, 2021, https://theforge.defence.gov.au/adf-philosophical-doctrine-military-ethics.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Australian Department of Defence, </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Defence Export Strategy</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>, Commonwealth of Australia, 2018.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Beard, Matthew. ‘Beyond Tallinn: The Code of the Cyberwarrior?’ in Allhoff F, Henschke A, and Strawser BJ (eds) </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Binary Bullets: The Ethics of Cyberwarfare</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>, New York: Oxford University Press, 2016, pp. 139–56.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Bellanova Rocco, Jacobsen, Katja Lindskov, and Monsees, Linda. ‘Taking the trouble: science, technology and security studies’, </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Critical Studies on Security</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> 8.2 (2020): 87–100.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Boeing. ‘Airpower Teaming System’, https://www.boeing.com/defense/airpower-teaming-system/index.page.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Buzan, Barry, Wæver, Ole and de Wilde Jaap. </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Security: A New Framework for Analysis</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>. Boulder: Lynne Reiner Publishers, 1998.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Clark, Robert and Jennings, Peter. ‘An Australian DARPA to Turbocharge Universities’ National Security Research: Securely Managed Defence-funded Research Partnerships in Five-Eyes Universities’, ASPI, 2021.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Department of Defence. ‘Memorandum for the Establishment of an Algorithmic Warfare Cross-Functional Team (Project Maven)’, 2017, https://www.govexec.com/media/gbc/docs/pdfs_edit/establishment_of_the_awcft_project_maven.pdf.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Department of Industry. ‘Growth opportunities. Department of Industry, Science, Energy and Resources’, 2021, https://www.industry.gov.au/data-and-publications/defence-national-manufacturing-priority-road-map/growth-opportunities.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Der Derian, James. </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Virtuous War: Mapping the Military-Industrial-Media-Entertainment Network</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>, 2nd edition, New York: Routledge, 2009.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Devitt, S. Kate. ‘</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Normative Epistemology for Lethal Autonomous Weapons Systems’ in </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Galliott, Jai, MacIntosh, Duncan and Ohlin, Jens David (eds) </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Lethal Autonomous Weapons: Re-Examining the Law and Ethics of Robotic Warfare</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>, Oxford: Oxford University Press, 2021, pp. 237–58.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Devitt, S. Kate, Scholz, Jason, Schless, Timo and Lewis, Larry (preprint). </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>‘Developing a Trusted Human-AI Network for Humanitarian Benefit’, </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Journal of Digital War</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> ‘My War’ special issue, 2022.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Enemark, Christian. </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Armed Drones and the Ethics of War: Military Virtue in a Post-Heroic Age</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>, New York: Routledge, 2014.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Galliott, Jai, MacIntosh, Duncan and Ohlin, Jens David (eds). </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Lethal Autonomous Weapons: Re-Examining the Law and Ethics of Robotic Warfare</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>, Oxford, New York: Oxford University Press, 2021.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Halpern, Orit. </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Beautiful Data: A History of Vision and Reason since 1945</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>, Durham: Duke University Press, 2015.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Howell, Alison. ‘Forget “Militarization”: Race, Disability and the “Martial Politics” of the Police and of the University’, </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>International Feminist Journal of Politics</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> 20.2 (2018): 117–36.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Liljefors, Max, Gregor Noll, and Daniel Steuer (eds). </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>War and Algorithm</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>, London; New York: Rowman &amp; Littlefield International, 2019.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Massingham, Eve. ‘Automation of the Spectrum, Automation and the Spectrum: Legal Challenges When Optimising Spectrum Use for Military Operations’, </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Law, Technology and Humans</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> 3.2 (2021): 91–106.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Ministers for the Department of Industry, Science, Energy and Resources. ‘Action Plan to supercharge research commercialisation’, 2022, https://www.minister.industry.gov.au/ministers/taylor/media-releases/action-plan-supercharge-research-commercialisation.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Packer, Jeremy and Joshua Reeves. </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Killer Apps: War, Media, Machine</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>, Durham: Duke University Press, 2020.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Phan, Thao, Jake Goldenfein, Monique Mann, and Declan Kuch. ‘Economies of Virtue: The Circulation of ‘Ethics’ in Big Tech’, </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Science as Culture</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> 31.1 (2021): 1–15.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Roberson, Tara, Stephen Bornstein, Rain Liivoja, Simon Ng, Jason Scholz, and Kate Devitt. ‘A Method for Ethical AI in Defence: A Case Study on Developing Trustworthy Autonomous Systems’, </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Journal of Responsible Technology</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> 11 (2022).</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Sadowski, Jathan. ‘Potemkin AI.’ </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Real Life</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>, 6 August 2018, https://reallifemag.com/potemkin-ai/.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Schwarz, Elke. </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Death Machines: The Ethics of Violent Technologies</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>, Manchester: Manchester University Press, 2018.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>———. ‘Silicon Valley Goes to War: Artificial Intelligence, Weapons Systems, and Moral Agency’, </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Philosophy Today</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> 65.3, (2021): 549–69.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Sharkey, Noel. ‘Automating Warfare: Lessons Learned from the Drones.’ </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Journal of Law, Information and Science</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> 21.2 (2011): 140–54.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Shepherd, Tory. ‘Australia’s Aukus Nuclear Submarines Could Cost as Much as $171bn, Report Finds’ </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Guardian</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>, 13 December 2021, sec. World news, https://www.theguardian.com/world/2021/dec/14/australias-aukus-nuclear-submarines-estimated-to-cost-at-least-70bn.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Suchman, Lucy. ‘Algorithmic Warfare and the Reinvention of Accuracy’, </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Critical Studies on Security</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> 8.2 (2020): 1–13.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Suchman, Lucy, Karolina Follis, and Jutta Weber. ‘Tracking and Targeting: Sociotechnologies of (In)Security’, </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Science, Technology, &amp; Human Values</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> 42.6 (2017): 983–1002.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Viseu, Ana. ‘Caring for Nanotechnology? Being an Integrated Social Scientist’, </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Social Studies of Science</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> 45.5 (2015): 642–64.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>
<Br />
<ParagraphStyleRange AppliedParagraphStyle="ParagraphStyle/Paragraph">
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content>Whittaker, Meredith. ‘The Steep Cost of Capture’, </Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="CharacterStyle/Italic">
    <Content>Interactions</Content>
  </CharacterStyleRange>
  <CharacterStyleRange AppliedCharacterStyle="$ID/NormalCharacterStyle">
    <Content> 28.6 (2021): 50–5.</Content>
  </CharacterStyleRange>
</ParagraphStyleRange>

  </Story>
  
</Document>
